{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install aiohttp==3.9.5 beautifulsoup4==4.12.3 faiss_cpu==1.8.0 mistralai==0.4.0 nest_asyncio==1.6.0 numpy==1.26.4 pandas==2.2.2 python-dotenv==1.0.1 requests==2.32.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "MISTRALL_API_KEY = os.getenv('MISTRAL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp \n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup \n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "import requests \n",
    "import re \n",
    "import pandas as pd \n",
    "import faiss \n",
    "import numpy as np \n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "total_results_to_fetch = 10 \n",
    "chunk_size = 1000 \n",
    "\n",
    "dataframe_out_path = \"temp.csv\"\n",
    "faiss_index_path = \"faiss_index.index\"\n",
    "\n",
    "mistral_api_key = MISTRALL_API_KEY \n",
    "client = MistralClient(api_key=mistral_api_key)\n",
    "\n",
    "async def fetch(session, url, params=None):\n",
    "    async with session.get(url, params=params, headers=headers) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def fetch_page(session, params, page_num, results):\n",
    "    print(f\"Fetching page: {page_num}\")\n",
    "    params[\"start\"] = (page_num - 1) * params[\"num\"]\n",
    "    html = await fetch(session, \"https://www.google.com/search\", params=params)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    for result in soup.select(\".tF2Cxc\"):\n",
    "        if len(results) >= total_results_to_fetch:\n",
    "            break\n",
    "        title = result.select_one(\".DKV0Md\").text\n",
    "        links = result.select_one(\".yuRUbf a\")[\"href\"]\n",
    "        \n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"link\": links\n",
    "        })\n",
    "\n",
    "async def fetch_content(session, url):\n",
    "    async with session.get(url, headers=headers, timeout=30) as response:\n",
    "        return await response.text()\n",
    "    \n",
    "async def fetch_all_content(urls): \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_content(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "    \n",
    "def get_all_text_from_url(url):\n",
    "    response = requests.get(url, headers=headers, timeout=30)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    for script in soup([\"script\", \"soup\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = \"\\n\".join(chunk for chunk in chunks if chunk)  \n",
    "    return text\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size):\n",
    "    sentences = re.split(r\"(?<=[.!?]) +\", text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for sentence in sentences: \n",
    "        if sum(len(s) for s in current_chunk) + len(sentence) < chunk_size:  \n",
    "            current_chunk.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "async def process_text_content(texts, chunk_size):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [loop.run_in_executor(None, split_text_into_chunks, text, chunk_size) for text in texts]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_embedding_from_mistral(client, text_chunk):\n",
    "    response = client.embeddings(model=\"mistral-embed\", input=text_chunk)\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "async def fetch_and_process_data(search_query):\n",
    "    params = {\n",
    "        \"q\": search_query,\n",
    "        \"num\": 100,\n",
    "        \"gl\": \"uk\",\n",
    "        \"hl\": \"en\",\n",
    "        \"start\": 0\n",
    "    } \n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        page_num = 0\n",
    "        results = []\n",
    "        while len(results) < total_results_to_fetch:\n",
    "            page_num += 1 \n",
    "            await fetch_page(session, params, page_num, results)\n",
    "\n",
    "        urls = [result[\"links\"] for result in results]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            texts = await asyncio.gather(\n",
    "                *[loop.run_in_executor(executor, get_all_text_from_url, url) for url in urls]\n",
    "            )\n",
    "\n",
    "        chunks_list = await process_text_content(texts, chunk_size)\n",
    "\n",
    "        embeddings_list = []\n",
    "        for chunks in chunks_list: \n",
    "            embeddings = await get_embedding_from_mistral(client, chunks)  \n",
    "            embeddings_list.append(embeddings)\n",
    "\n",
    "        data = []\n",
    "        for i, result in enumerate(results):\n",
    "            if i >= len(embeddings_list):\n",
    "                print(f\"Error: No embeddings returned for result {i}\")\n",
    "                continue\n",
    "            for j, chunk in enumerate(chunks_list[i]):\n",
    "                if j >= len(embeddings_list[i]):\n",
    "                    print(f\"Error: No embedding returned for chunk {j} of result {i}\")\n",
    "                    continue\n",
    "                data.append({\n",
    "                    \"title\": result[\"title\"],\n",
    "                    \"link\": result[\"link\"],\n",
    "                    \"chunk\": chunk,\n",
    "                    \"embedding\": embeddings_list[i][j]\n",
    "                })\\\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(dataframe_out_path, index=False)\n",
    "\n",
    "        # FAISS indexing\n",
    "        dimension = len(embeddings_list[0][0])\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "        embeddings = np.array([entry[\"embedding\"] for entry in data], dtype=np.float32)\n",
    "        index.add(embeddings)\n",
    "\n",
    "        faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "await fetch_and_process_data(\"What is the latest news on Mistral AI?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
